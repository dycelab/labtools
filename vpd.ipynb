{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import ee\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from zipfile import BadZipfile\n",
    "\n",
    "import requests\n",
    "\n",
    "#ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>SURVEY_YEA</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>POLYGON ((-108.76696 37.89542, -108.76238 37.8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  SURVEY_YEA                                           geometry\n",
       "0   1        2023  POLYGON ((-108.76696 37.89542, -108.76238 37.8..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## take the ads file\n",
    "gdf = gpd.read_file('./input/sanjuan_NF_boundary.shp')\n",
    "#gdf.head()\n",
    "#gdf.head()\n",
    "#gdf = gdf[['id', 'SURVEY_YEA', 'geometry']]\n",
    "gdf['id'] = 1\n",
    "gdf['SURVEY_YEA'] = 2023\n",
    "gdf = gdf[['id', 'SURVEY_YEA', 'geometry']]\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter if the API breaks\n",
    "#gdf = gdf[499:]\n",
    "#gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "start is 2012-01-01 end is 2023-12-31\n",
      "./cwd/images/1\n",
      "Folder in place already\n",
      "201201\n",
      "201202\n",
      "201203\n",
      "201204\n",
      "201205\n",
      "201206\n",
      "201207\n",
      "201208\n",
      "201209\n",
      "201210\n",
      "201211\n",
      "201212\n",
      "201301\n",
      "201302\n",
      "201303\n",
      "201304\n",
      "201305\n",
      "201306\n",
      "201307\n",
      "201308\n",
      "201309\n",
      "201310\n",
      "201311\n",
      "201312\n",
      "201401\n",
      "201402\n",
      "201403\n",
      "201404\n",
      "201405\n",
      "201406\n",
      "201407\n",
      "201408\n",
      "201409\n",
      "201410\n",
      "201411\n",
      "201412\n",
      "201501\n",
      "201502\n",
      "201503\n",
      "201504\n",
      "201505\n",
      "201506\n",
      "201507\n",
      "201508\n",
      "201509\n",
      "201510\n",
      "201511\n",
      "201512\n",
      "201601\n",
      "201602\n",
      "201603\n",
      "201604\n",
      "201605\n",
      "201606\n",
      "201607\n",
      "201608\n",
      "201609\n",
      "201610\n",
      "201611\n",
      "201612\n",
      "201701\n",
      "201702\n",
      "201703\n",
      "201704\n",
      "201705\n",
      "201706\n",
      "201707\n",
      "201708\n",
      "201709\n",
      "201710\n",
      "201711\n",
      "201712\n",
      "201801\n",
      "201802\n",
      "201803\n",
      "201804\n",
      "201805\n",
      "201806\n",
      "201807\n",
      "201808\n",
      "201809\n",
      "201810\n",
      "201811\n",
      "201812\n",
      "201901\n",
      "201902\n",
      "201903\n",
      "201904\n",
      "201905\n",
      "201906\n",
      "201907\n",
      "201908\n",
      "201909\n",
      "201910\n",
      "201911\n",
      "201912\n",
      "202001\n",
      "202002\n",
      "202003\n",
      "202004\n",
      "202005\n",
      "202006\n",
      "202007\n",
      "202008\n",
      "202009\n",
      "202010\n",
      "202011\n",
      "202012\n",
      "202101\n",
      "202102\n",
      "202103\n",
      "202104\n",
      "202105\n",
      "202106\n",
      "202107\n",
      "202108\n",
      "202109\n",
      "202110\n",
      "202111\n",
      "202112\n",
      "202201\n",
      "202202\n",
      "202203\n",
      "202204\n",
      "202205\n",
      "202206\n",
      "202207\n",
      "202208\n",
      "202209\n",
      "202210\n",
      "202211\n",
      "202212\n",
      "202301\n",
      "202302\n",
      "202303\n",
      "202304\n",
      "202305\n",
      "202306\n",
      "202307\n",
      "202308\n",
      "202309\n",
      "202310\n",
      "202311\n",
      "202312\n",
      "Down load succefull\n"
     ]
    }
   ],
   "source": [
    "for index, row in gdf.iterrows():\n",
    "    print(row['id'])\n",
    "\n",
    "    end = row['SURVEY_YEA']\n",
    "    start = end - 11\n",
    "\n",
    "    start_date = str(start)+'-01-01'\n",
    "    end_date = str(end)+'-12-31'\n",
    "\n",
    "    print(f'start is {start_date} end is {end_date}')\n",
    "\n",
    "    corners = list(row['geometry'].exterior.coords)\n",
    "    new_polygon = Polygon(corners)\n",
    "\n",
    "    aoi  = ee.Geometry.Polygon([list(coord) for coord in corners])\n",
    "\n",
    "    pre_collection = ee.ImageCollection('IDAHO_EPSCOR/TERRACLIMATE').filterBounds(aoi).filterDate(start_date, end_date).select('def')\n",
    "\n",
    "    #summer_collection = pre_collection.filter(ee.Filter.calendarRange(6, 8, 'month'))\n",
    "    summer_collection = pre_collection\n",
    "\n",
    "\n",
    "    image_list = summer_collection.toList(summer_collection.size())\n",
    "\n",
    "    # create folder for images\n",
    "    ads_id = row['id']\n",
    "    folder_path  = './cwd/images/'+str(ads_id)\n",
    "    print(folder_path)\n",
    "    # create folders\n",
    "    try:\n",
    "        os.makedirs(folder_path)\n",
    "    except:\n",
    "        print('Folder in place already')\n",
    "    # number of images in collection for aoi\n",
    "    num_images = summer_collection.size().getInfo()\n",
    "    for item in range(0, num_images):\n",
    "        # take images\n",
    "        filter_image = ee.Image(image_list.get(item))\n",
    "        # clip to aoi\n",
    "        pre_image = filter_image.clip(aoi)#.unmask()\n",
    "        # image name\n",
    "        im_name = str(pre_image.get('system:index').getInfo())\n",
    "        print(im_name)\n",
    "        # take url\n",
    "        try:\n",
    "            url = pre_image.getDownloadURL({'scale':4000,\n",
    "                                                    'filePerBand':False, \n",
    "                                                    'region':aoi,\n",
    "                                                    'crs':'EPSG:4326', \n",
    "                                                    'maxPixels': 1e13})\n",
    "            #print(url)\n",
    "            r = requests.get(url)\n",
    "            with open(folder_path+'/'+im_name+'.zip', 'wb') as f:\n",
    "                f.write(r.content)\n",
    "        except:\n",
    "            print('no images avialable')\n",
    "            continue\n",
    "        # extract the zipfile here\n",
    "        zip_file = glob.glob('./cwd/images/'+str(ads_id)+'/*zip')\n",
    "        try:\n",
    "            zf = ZipFile(zip_file[0])\n",
    "            zf.extractall('./cwd/images/'+str(ads_id))\n",
    "            os.remove(zip_file[0])\n",
    "        except BadZipfile:\n",
    "            os.remove(zip_file[0])\n",
    "\n",
    "    print('Down load succefull')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as ras\n",
    "from rasterstats import zonal_stats\n",
    "from rasterio.enums import Resampling as resa\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "./vpd/images/1/200006.tif\n",
      "Processing completed for 2000\n",
      "./vpd/images/1/200007.tif\n",
      "Processing completed for 2000\n",
      "./vpd/images/1/200008.tif\n",
      "Processing completed for 2000\n",
      "2001\n",
      "./vpd/images/1/200106.tif\n",
      "Processing completed for 2001\n",
      "./vpd/images/1/200107.tif\n",
      "Processing completed for 2001\n",
      "./vpd/images/1/200108.tif\n",
      "Processing completed for 2001\n",
      "2002\n",
      "./vpd/images/1/200206.tif\n",
      "Processing completed for 2002\n",
      "./vpd/images/1/200207.tif\n",
      "Processing completed for 2002\n",
      "./vpd/images/1/200208.tif\n",
      "Processing completed for 2002\n",
      "2003\n",
      "./vpd/images/1/200306.tif\n",
      "Processing completed for 2003\n",
      "./vpd/images/1/200307.tif\n",
      "Processing completed for 2003\n",
      "./vpd/images/1/200308.tif\n",
      "Processing completed for 2003\n",
      "2004\n",
      "./vpd/images/1/200406.tif\n",
      "Processing completed for 2004\n",
      "./vpd/images/1/200407.tif\n",
      "Processing completed for 2004\n",
      "./vpd/images/1/200408.tif\n",
      "Processing completed for 2004\n",
      "2005\n",
      "./vpd/images/1/200506.tif\n",
      "Processing completed for 2005\n",
      "./vpd/images/1/200507.tif\n",
      "Processing completed for 2005\n",
      "./vpd/images/1/200508.tif\n",
      "Processing completed for 2005\n",
      "2006\n",
      "./vpd/images/1/200606.tif\n",
      "Processing completed for 2006\n",
      "./vpd/images/1/200607.tif\n",
      "Processing completed for 2006\n",
      "./vpd/images/1/200608.tif\n",
      "Processing completed for 2006\n",
      "2007\n",
      "./vpd/images/1/200706.tif\n",
      "Processing completed for 2007\n",
      "./vpd/images/1/200707.tif\n",
      "Processing completed for 2007\n",
      "./vpd/images/1/200708.tif\n",
      "Processing completed for 2007\n",
      "2008\n",
      "./vpd/images/1/200806.tif\n",
      "Processing completed for 2008\n",
      "./vpd/images/1/200807.tif\n",
      "Processing completed for 2008\n",
      "./vpd/images/1/200808.tif\n",
      "Processing completed for 2008\n",
      "2009\n",
      "./vpd/images/1/200906.tif\n",
      "Processing completed for 2009\n",
      "./vpd/images/1/200907.tif\n",
      "Processing completed for 2009\n",
      "./vpd/images/1/200908.tif\n",
      "Processing completed for 2009\n",
      "2010\n",
      "./vpd/images/1/201006.tif\n",
      "Processing completed for 2010\n",
      "./vpd/images/1/201007.tif\n",
      "Processing completed for 2010\n",
      "./vpd/images/1/201008.tif\n",
      "Processing completed for 2010\n",
      "2011\n",
      "./vpd/images/1/201106.tif\n",
      "Processing completed for 2011\n",
      "./vpd/images/1/201107.tif\n",
      "Processing completed for 2011\n",
      "./vpd/images/1/201108.tif\n",
      "Processing completed for 2011\n",
      "2012\n",
      "./vpd/images/1/201206.tif\n",
      "Processing completed for 2012\n",
      "./vpd/images/1/201207.tif\n",
      "Processing completed for 2012\n",
      "./vpd/images/1/201208.tif\n",
      "Processing completed for 2012\n",
      "2013\n",
      "./vpd/images/1/201306.tif\n",
      "Processing completed for 2013\n",
      "./vpd/images/1/201307.tif\n",
      "Processing completed for 2013\n",
      "./vpd/images/1/201308.tif\n",
      "Processing completed for 2013\n",
      "2014\n",
      "./vpd/images/1/201406.tif\n",
      "Processing completed for 2014\n",
      "./vpd/images/1/201407.tif\n",
      "Processing completed for 2014\n",
      "./vpd/images/1/201408.tif\n",
      "Processing completed for 2014\n",
      "2015\n",
      "./vpd/images/1/201506.tif\n",
      "Processing completed for 2015\n",
      "./vpd/images/1/201507.tif\n",
      "Processing completed for 2015\n",
      "./vpd/images/1/201508.tif\n",
      "Processing completed for 2015\n",
      "2016\n",
      "./vpd/images/1/201606.tif\n",
      "Processing completed for 2016\n",
      "./vpd/images/1/201607.tif\n",
      "Processing completed for 2016\n",
      "./vpd/images/1/201608.tif\n",
      "Processing completed for 2016\n",
      "2017\n",
      "./vpd/images/1/201706.tif\n",
      "Processing completed for 2017\n",
      "./vpd/images/1/201707.tif\n",
      "Processing completed for 2017\n",
      "./vpd/images/1/201708.tif\n",
      "Processing completed for 2017\n",
      "2018\n",
      "./vpd/images/1/201806.tif\n",
      "Processing completed for 2018\n",
      "./vpd/images/1/201807.tif\n",
      "Processing completed for 2018\n",
      "./vpd/images/1/201808.tif\n",
      "Processing completed for 2018\n",
      "2019\n",
      "./vpd/images/1/201906.tif\n",
      "Processing completed for 2019\n",
      "./vpd/images/1/201907.tif\n",
      "Processing completed for 2019\n",
      "./vpd/images/1/201908.tif\n",
      "Processing completed for 2019\n",
      "2020\n",
      "./vpd/images/1/202006.tif\n",
      "Processing completed for 2020\n",
      "./vpd/images/1/202007.tif\n",
      "Processing completed for 2020\n",
      "./vpd/images/1/202008.tif\n",
      "Processing completed for 2020\n",
      "2021\n",
      "./vpd/images/1/202106.tif\n",
      "Processing completed for 2021\n",
      "./vpd/images/1/202107.tif\n",
      "Processing completed for 2021\n",
      "./vpd/images/1/202108.tif\n",
      "Processing completed for 2021\n",
      "2022\n",
      "./vpd/images/1/202206.tif\n",
      "Processing completed for 2022\n",
      "./vpd/images/1/202207.tif\n",
      "Processing completed for 2022\n",
      "./vpd/images/1/202208.tif\n",
      "Processing completed for 2022\n",
      "2023\n",
      "./vpd/images/1/202306.tif\n",
      "Processing completed for 2023\n",
      "./vpd/images/1/202307.tif\n",
      "Processing completed for 2023\n",
      "./vpd/images/1/202308.tif\n",
      "Processing completed for 2023\n"
     ]
    }
   ],
   "source": [
    "# list dir images\n",
    "image_list = glob.glob('./vpd/images/1/*tif')\n",
    "# Extract the date part (YYYYMM format) and sort by it\n",
    "sorted_filenames = sorted(image_list, key=lambda x: re.findall(r'\\d{6}', x)[0])\n",
    "\n",
    "\n",
    "for i in range (2000, 2024):\n",
    "       print(i)\n",
    "        # empty list to collect bands\n",
    "       band_list = []\n",
    "       for path in sorted_filenames:\n",
    "              if str(i) == path.split('/')[4][:4]:\n",
    "                     print(path)\n",
    "                     # read each file\n",
    "                     src = ras.open(path)\n",
    "                     band = src.read(1)\n",
    "                     band_scaled = band * 0.01\n",
    "                     band_scaled = band_scaled.astype(np.float32)\n",
    "                     #print(band)\n",
    "                     band_list.append(band_scaled)\n",
    "                     # data stack\n",
    "                     combined_data = np.dstack(band_list)\n",
    "                     combined_data = combined_data.astype(np.float32)\n",
    "                     # take mean image\n",
    "                     #mean_data = np.nanmean(combined_data, axis=2)\n",
    "\n",
    "                     sum_data = np.sum(combined_data, axis=2)\n",
    "\n",
    "\n",
    "                     # now zonal stats\n",
    "                     ds_profile = src.profile\n",
    "                     ds_affine = ds_profile['transform']\n",
    "                     #stats = zonal_stats(gdf, mean_data, affine=ds_affine, nodata=0, stats=\"mean\")\n",
    "                     #zonal_mean = stats[0]['mean']\n",
    "                     # saving path \n",
    "                     save_path = './vpd/composite/'+str(i)+'.tif'\n",
    "\n",
    "                                   #save images\n",
    "                     with ras.Env():\n",
    "                            # image profile\n",
    "                            profile = src.profile\n",
    "                            # update profile\n",
    "                            profile.update(\n",
    "                                   dtype= ras.float32,\n",
    "                                   count =1,\n",
    "                                   compress = 'lzw',\n",
    "                                   nodata=0\n",
    "                                   )\n",
    "                     with ras.open(save_path, 'w', **profile) as dst:\n",
    "                            dst.write(sum_data.astype(ras.float32), 1)\n",
    "                            dst.close()\n",
    "                     print(f'Processing completed for {i}')\n",
    "\n",
    "                     src.close()\n",
    "              else:\n",
    "                     continue\n",
    "       #print(zonal_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>PROCLAIMED</th>\n",
       "      <th>FORESTNAME</th>\n",
       "      <th>GIS_ACRES</th>\n",
       "      <th>SHAPEAREA</th>\n",
       "      <th>SHAPELEN</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194196</td>\n",
       "      <td>295494010328</td>\n",
       "      <td>San Juan National Forest</td>\n",
       "      <td>2093914.595</td>\n",
       "      <td>0.863366</td>\n",
       "      <td>9.020643</td>\n",
       "      <td>POLYGON ((-108.76696 37.89542, -108.76238 37.8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID    PROCLAIMED                FORESTNAME    GIS_ACRES  SHAPEAREA  \\\n",
       "0    194196  295494010328  San Juan National Forest  2093914.595   0.863366   \n",
       "\n",
       "   SHAPELEN                                           geometry  \n",
       "0  9.020643  POLYGON ((-108.76696 37.89542, -108.76238 37.8...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf = gpd.read_file('./input/sanjuan_NF_boundary.shp')\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2.939192927293535\n",
      "2001\n",
      "2.8111960919983185\n",
      "2002\n",
      "2.8678027781670403\n",
      "2003\n",
      "2.851659207422459\n",
      "2004\n",
      "2.6756053519712255\n",
      "2005\n",
      "2.6866068248435164\n",
      "2006\n",
      "2.7407025848981688\n",
      "2007\n",
      "2.937414058120796\n",
      "2008\n",
      "2.755455940828195\n",
      "2009\n",
      "2.4431988041853514\n",
      "2010\n",
      "2.5500747384155455\n",
      "2011\n",
      "2.6805830472253365\n",
      "2012\n",
      "2.931225695417601\n",
      "2013\n",
      "2.4765769148799515\n",
      "2014\n",
      "2.4097157750607248\n",
      "2015\n",
      "2.4309415945557737\n",
      "2016\n",
      "3.1567412007193574\n",
      "2017\n",
      "3.1954708812126307\n",
      "2018\n",
      "3.50146484375\n",
      "2019\n",
      "3.6051421343656576\n",
      "2020\n",
      "3.6284303764947685\n",
      "2021\n",
      "3.3936773052130045\n",
      "2022\n",
      "2.6322121841134156\n",
      "2023\n",
      "3.635007576022982\n"
     ]
    }
   ],
   "source": [
    "# zonal stats\n",
    "# list images in composited\n",
    "comp_list = glob.glob('./vpd/composite/*.tif')\n",
    "sorted_filenames = sorted(comp_list, key=lambda x: re.findall(r'\\d{4}', x)[0])\n",
    "\n",
    "year_list = []\n",
    "clim_list = []\n",
    "for file in sorted_filenames:\n",
    "    year = file.split('/')[3][:4]\n",
    "    src = ras.open(file)\n",
    "    band = src.read(1)\n",
    "\n",
    "    ds_profile = src.profile\n",
    "    ds_affine = ds_profile['transform']\n",
    "    stats = zonal_stats(gdf, band, affine=ds_affine, nodata=0, stats=\"mean\")\n",
    "    zonal_mean = stats[0]['mean']\n",
    "    year_list.append(year)\n",
    "    clim_list.append(zonal_mean)\n",
    "    print(year)\n",
    "    print(zonal_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>vpd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>2.939193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>2.811196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>2.867803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>2.851659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>2.675605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2005</td>\n",
       "      <td>2.686607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2006</td>\n",
       "      <td>2.740703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2007</td>\n",
       "      <td>2.937414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2008</td>\n",
       "      <td>2.755456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009</td>\n",
       "      <td>2.443199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010</td>\n",
       "      <td>2.550075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2011</td>\n",
       "      <td>2.680583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012</td>\n",
       "      <td>2.931226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013</td>\n",
       "      <td>2.476577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014</td>\n",
       "      <td>2.409716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015</td>\n",
       "      <td>2.430942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016</td>\n",
       "      <td>3.156741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>3.195471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018</td>\n",
       "      <td>3.501465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019</td>\n",
       "      <td>3.605142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020</td>\n",
       "      <td>3.628430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021</td>\n",
       "      <td>3.393677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2022</td>\n",
       "      <td>2.632212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023</td>\n",
       "      <td>3.635008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year       vpd\n",
       "0   2000  2.939193\n",
       "1   2001  2.811196\n",
       "2   2002  2.867803\n",
       "3   2003  2.851659\n",
       "4   2004  2.675605\n",
       "5   2005  2.686607\n",
       "6   2006  2.740703\n",
       "7   2007  2.937414\n",
       "8   2008  2.755456\n",
       "9   2009  2.443199\n",
       "10  2010  2.550075\n",
       "11  2011  2.680583\n",
       "12  2012  2.931226\n",
       "13  2013  2.476577\n",
       "14  2014  2.409716\n",
       "15  2015  2.430942\n",
       "16  2016  3.156741\n",
       "17  2017  3.195471\n",
       "18  2018  3.501465\n",
       "19  2019  3.605142\n",
       "20  2020  3.628430\n",
       "21  2021  3.393677\n",
       "22  2022  2.632212\n",
       "23  2023  3.635008"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clim_df = pd.DataFrame()\n",
    "clim_df['year'] = year_list\n",
    "clim_df['vpd'] = clim_list\n",
    "clim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_df.to_csv('./vpd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>vpd</th>\n",
       "      <th>pdsi</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>2.939193</td>\n",
       "      <td>-7.540778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>2.811196</td>\n",
       "      <td>2.001001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>2.867803</td>\n",
       "      <td>-15.571839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>2.851659</td>\n",
       "      <td>-8.271898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>2.675605</td>\n",
       "      <td>-5.071943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2005</td>\n",
       "      <td>2.686607</td>\n",
       "      <td>2.706338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2006</td>\n",
       "      <td>2.740703</td>\n",
       "      <td>-7.021046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2007</td>\n",
       "      <td>2.937414</td>\n",
       "      <td>3.383348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2008</td>\n",
       "      <td>2.755456</td>\n",
       "      <td>2.204634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009</td>\n",
       "      <td>2.443199</td>\n",
       "      <td>0.525097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010</td>\n",
       "      <td>2.550075</td>\n",
       "      <td>-2.692684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2011</td>\n",
       "      <td>2.680583</td>\n",
       "      <td>-2.530269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012</td>\n",
       "      <td>2.931226</td>\n",
       "      <td>-9.230479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013</td>\n",
       "      <td>2.476577</td>\n",
       "      <td>-7.067967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014</td>\n",
       "      <td>2.409716</td>\n",
       "      <td>6.351465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015</td>\n",
       "      <td>2.430942</td>\n",
       "      <td>16.397100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016</td>\n",
       "      <td>3.156741</td>\n",
       "      <td>9.915546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>3.195471</td>\n",
       "      <td>-1.984753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018</td>\n",
       "      <td>3.501465</td>\n",
       "      <td>-14.017488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019</td>\n",
       "      <td>3.605142</td>\n",
       "      <td>9.973990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020</td>\n",
       "      <td>3.628430</td>\n",
       "      <td>-14.146770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021</td>\n",
       "      <td>3.393677</td>\n",
       "      <td>-13.165605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2022</td>\n",
       "      <td>2.632212</td>\n",
       "      <td>-7.670703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023</td>\n",
       "      <td>3.635008</td>\n",
       "      <td>-1.809866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year       vpd       pdsi  Unnamed: 3  Unnamed: 4 Unnamed: 5 Unnamed: 6\n",
       "0   2000  2.939193  -7.540778         NaN         NaN        NaN        NaN\n",
       "1   2001  2.811196   2.001001         NaN         NaN        NaN        NaN\n",
       "2   2002  2.867803 -15.571839         NaN         NaN        NaN        NaN\n",
       "3   2003  2.851659  -8.271898         NaN         NaN        NaN        NaN\n",
       "4   2004  2.675605  -5.071943         NaN         NaN        NaN        NaN\n",
       "5   2005  2.686607   2.706338         NaN         NaN        NaN        NaN\n",
       "6   2006  2.740703  -7.021046         NaN         NaN        NaN        NaN\n",
       "7   2007  2.937414   3.383348         NaN         NaN        NaN        NaN\n",
       "8   2008  2.755456   2.204634         NaN         NaN        NaN        NaN\n",
       "9   2009  2.443199   0.525097         NaN         NaN        NaN        NaN\n",
       "10  2010  2.550075  -2.692684         NaN         NaN                   NaN\n",
       "11  2011  2.680583  -2.530269         NaN         NaN        NaN        NaN\n",
       "12  2012  2.931226  -9.230479         NaN         NaN        NaN        NaN\n",
       "13  2013  2.476577  -7.067967         NaN         NaN        NaN        NaN\n",
       "14  2014  2.409716   6.351465         NaN         NaN        NaN        NaN\n",
       "15  2015  2.430942  16.397100         NaN         NaN        NaN           \n",
       "16  2016  3.156741   9.915546         NaN         NaN        NaN        NaN\n",
       "17  2017  3.195471  -1.984753         NaN         NaN        NaN        NaN\n",
       "18  2018  3.501465 -14.017488         NaN         NaN        NaN        NaN\n",
       "19  2019  3.605142   9.973990         NaN         NaN        NaN        NaN\n",
       "20  2020  3.628430 -14.146770         NaN         NaN        NaN        NaN\n",
       "21  2021  3.393677 -13.165605         NaN         NaN        NaN        NaN\n",
       "22  2022  2.632212  -7.670703         NaN         NaN        NaN        NaN\n",
       "23  2023  3.635008  -1.809866         NaN         NaN        NaN        NaN"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open dfs\n",
    "combined_df = pd.read_csv('./SJ.csv')\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
